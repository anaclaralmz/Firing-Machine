{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_g6gdZgJQMT"
      },
      "source": [
        "Este é o Notebook oficial do grupo 4, aqui teremos:\n",
        "- um resumo da análise de dados;\n",
        "- os códigos responsáveis pelo processamento (tratamento) dos dados da tabela;\n",
        "- o modelo preditivo;\n",
        "\n",
        "Em todos os códigos, há comentários suficientes para explicar o objetivo e funcionamento da função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhqWt_FOzBgL"
      },
      "source": [
        "# Importações e instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72CJ2R6mtgNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cd2d20-21bb-4738-c80e-4afb2b72f4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dataprep in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: pandas<2.0,>=1.1 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.3.5)\n",
            "Requirement already satisfied: python-stdnum<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.17)\n",
            "Requirement already satisfied: jinja2<4,>=3 in /usr/local/lib/python3.7/dist-packages (from dataprep) (3.1.2)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.8.2.2)\n",
            "Requirement already satisfied: metaphone<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from dataprep) (0.6)\n",
            "Requirement already satisfied: flask<3,>=2 in /usr/local/lib/python3.7/dist-packages (from dataprep) (2.2.2)\n",
            "Requirement already satisfied: varname<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from dataprep) (0.8.3)\n",
            "Requirement already satisfied: regex<2022.0.0,>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from dataprep) (2021.11.10)\n",
            "Requirement already satisfied: dask[array,dataframe,delayed]<2022.0,>=2021.11 in /usr/local/lib/python3.7/dist-packages (from dataprep) (2021.12.0)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0,>=1.4.32 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.4.40)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.7/dist-packages (from dataprep) (3.8.1)\n",
            "Requirement already satisfied: bokeh<3,>=2 in /usr/local/lib/python3.7/dist-packages (from dataprep) (2.3.3)\n",
            "Requirement already satisfied: pystache<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dataprep) (0.6.0)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.7 in /usr/local/lib/python3.7/dist-packages (from dataprep) (0.9.8)\n",
            "Requirement already satisfied: scipy<=1.7.1 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.7.1)\n",
            "Requirement already satisfied: flask_cors<4.0.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from dataprep) (3.0.10)\n",
            "Requirement already satisfied: jsonpath-ng<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.5.3)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.9.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.7/dist-packages (from dataprep) (4.64.0)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.7/dist-packages (from dataprep) (7.7.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.7 in /usr/local/lib/python3.7/dist-packages (from dataprep) (3.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.7/dist-packages (from dataprep) (1.21.6)\n",
            "Requirement already satisfied: python-Levenshtein<0.13.0,>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from dataprep) (0.12.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->dataprep) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->dataprep) (6.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->dataprep) (5.1.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->dataprep) (21.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->dataprep) (7.1.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<2022.0,>=2021.11->dataprep) (2022.8.1)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<2022.0,>=2021.11->dataprep) (1.5.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<2022.0,>=2021.11->dataprep) (0.12.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<2022.0,>=2021.11->dataprep) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=2->dataprep) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=2->dataprep) (2.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=2->dataprep) (4.12.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=2->dataprep) (2.2.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors<4.0.0,>=3.0.10->dataprep) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6.0->flask<3,>=2->dataprep) (3.8.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.6.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.1.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.3.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (6.1.12)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2<4,>=3->dataprep) (2.1.1)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0,>=1.5->dataprep) (3.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.7->dataprep) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh<3,>=2->dataprep) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.1->dataprep) (2022.2.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[array,dataframe,delayed]<2022.0,>=2021.11->dataprep) (1.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.5)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy<2.0.0,>=1.4.32->dataprep) (1.1.3)\n",
            "Requirement already satisfied: asttokens<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->dataprep) (2.0.8)\n",
            "Requirement already satisfied: executing<0.9.0,>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->dataprep) (0.8.3)\n",
            "Requirement already satisfied: pure_eval<1.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->dataprep) (0.2.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.11.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.4.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (23.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud<2.0,>=1.8->dataprep) (3.2.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->dataprep) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (0.11.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.6.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.16.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.9.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moment in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: dateparser>=0.7 in /usr/local/lib/python3.7/dist-packages (from moment) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from moment) (2022.2.1)\n",
            "Requirement already satisfied: times>=0.7 in /usr/local/lib/python3.7/dist-packages (from moment) (0.7)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser>=0.7->moment) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser>=0.7->moment) (2.8.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser>=0.7->moment) (2021.11.10)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.7/dist-packages (from times>=0.7->moment) (1.2.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from arrow->times>=0.7->moment) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser>=0.7->moment) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dataprep\n",
        "!pip install moment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYTaVF6MzI3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd163c44-c831-43b1-e52a-da3906bc0d2a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Bibliotecas \n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import moment\n",
        "\n",
        "## Bibliotecas para os gráficos\n",
        "import matplotlib.pyplot as plt #geração de gráficos\n",
        "import seaborn as sns #template de gráficos\n",
        "import plotly.express as px #geração de gráficos dinâmicos\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Modelos preditivos:\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree model\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN model\n",
        "from sklearn import svm # SVM model\n",
        "from sklearn.naive_bayes import GaussianNB # naive bayes model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "#### Métricas de avaliação\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "py.init_notebook_mode(connected=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS-ug5syzYDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de8f7b7-5e61-482b-e08c-1da9a77b50ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectando ao google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "content_link = '/content/drive/Shareddrives/G444 Drive/docs everymind/Base Colaboradores Everymind_Inteli_2020 a 2022vModelo Preditivo.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4k4OMn7z-id"
      },
      "outputs": [],
      "source": [
        "# Importando as planilhas\n",
        "df1 = pd.read_excel(content_link)\n",
        "df2 = pd.read_excel(content_link, sheet_name = 'Reconhecimento')\n",
        "df3 = pd.read_excel(content_link, sheet_name = 'Ambiente de Trabalho 27.07')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDlukObZJq2m"
      },
      "source": [
        "# Análise de Dados - Resumo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3yDIKRaJuaC"
      },
      "source": [
        "# Tratamento de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0cMmH4y6mCA"
      },
      "source": [
        "Resumo da seção:\n",
        "- Modificação de dados \n",
        "- Categorização\n",
        "- Derivação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN1QLFX5Jnuh"
      },
      "source": [
        "## Modificação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyHcP7Bhu19v"
      },
      "source": [
        "- Eliminiação de espaços\n",
        "- Tipificação de dados (como datas em string para datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxLeGg3ztQ9Y"
      },
      "outputs": [],
      "source": [
        "# Aqui percorremos todas as linhas das colunas e fazer a alteração de onde possui espaço em branco e substituir para vazio \n",
        "# (percorremos apenas linhas em string, por isso o argumento 'object' e o atributo str)\n",
        "for i in df1.select_dtypes(include = 'object').columns.drop('Dt Admissao'):\n",
        "  df1[i] = df1[i].str.replace(' ','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUHPXtav0DW_"
      },
      "outputs": [],
      "source": [
        "for i in df2.select_dtypes(include = 'object'):\n",
        "  df2[i] = df2[i].str.replace(' ','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDFcpZLdvsDW"
      },
      "outputs": [],
      "source": [
        "# Aqui substituímos o texto de \"PessoaColaboradora\" de todas as linhas da coluna 'Nome Completo' por vazio \n",
        "# (isso tem como objetivo obter apenas o número do colaborador)\n",
        "for i in range(0, len(df1['Nome Completo'])):\n",
        "  df1['Nome Completo'][i] = df1['Nome Completo'][i].replace('PessoaColaboradora', '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.rename(columns={'Matrícula': 'Matricula'})\n",
        "df1['Estagnação'] = 0"
      ],
      "metadata": {
        "id": "5u0jasuhz5fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKVNo8XN0A3-"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(df2['Codinome'])):\n",
        "  df2['Codinome'][i] = df2['Codinome'][i].replace('PessoaColaboradora', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqb2BwM-4RJe"
      },
      "outputs": [],
      "source": [
        "#Substituindo os valores das colunas da tabela 2 por valores numéricos\n",
        "for column in df2.drop(['Data de Admissão',\t'Data Vigência', 'Novo Salario'], axis=1):\n",
        "  df2[column] = preprocessing.LabelEncoder().fit(df2[column]).transform(df2[column])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jShGtzlKKN_D"
      },
      "source": [
        "## Categorização\n",
        "Aqui categorizamos os dados para numérico para tratar melhor com o modelo preditivo (como categorizar Tipo de Saída dos funcionários)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zujrRsZF7XQo"
      },
      "outputs": [],
      "source": [
        "# Categorização do gênero dos funcionários\n",
        "# 0 significa Masculino\n",
        "# 1 significa Feminino\n",
        "df1['Genero_Numerico'] = (df1['Genero']\n",
        "                          .replace('Masculino', 0)\n",
        "                          .replace('Feminino', 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d02_7thpQDPO"
      },
      "outputs": [],
      "source": [
        "# Categorização do tipo de saída dos funcionários\n",
        "# 0 significa ativo\n",
        "# 1 significa rescizão de contrato por pedido de demissão\n",
        "# 2 significa rescisão de contrato por demissão\n",
        "# 3 significa demissão\n",
        "# 4 significa pedido de demissão\n",
        "df1['Tipo_Saida_Numerico'] = (df1['Tipo Saida']\n",
        "                              .fillna(0)\n",
        "                              .replace('RescisaoContratoExp-Dispensa', 1)\n",
        "                              .replace('RescisaoContratoExp-Pedido', 2)\n",
        "                              .replace('DispensasemJustaCausa', 3)\n",
        "                              .replace('PedidodeDemissão', 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKUQS3LZJJBr"
      },
      "outputs": [],
      "source": [
        "# Categorização dos Estados para futuros cruzamentos de dados\n",
        "df1['Estado_Numerico'] = preprocessing.LabelEncoder().fit_transform(df1['Estado'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMN_QXB0Tk2s"
      },
      "outputs": [],
      "source": [
        "# Categorização das Regiões (agrupando os Estados)\n",
        "# '1' para Norte\n",
        "# '2' para Nordeste\n",
        "# '3' para Centro-Oeste\n",
        "# '4' para Sudeste\n",
        "# '5' para Sul\n",
        "df1['Regiao_Numerico'] = (df1['Estado']\n",
        "                       # Norte\n",
        "                       .replace('AM', 1)\n",
        "                       .replace('RR', 1)\n",
        "                       .replace('AC' , 1)\n",
        "                       .replace('RO', 1)\n",
        "                       .replace('AP', 1)\n",
        "                       .replace('PA', 1)\n",
        "                       .replace('TO', 1)\n",
        "                       # Nordeste\n",
        "                       .replace('MA', 2)\n",
        "                       .replace('CE', 2)\n",
        "                       .replace('PI', 1)\n",
        "                       .replace('RN', 1)\n",
        "                       .replace('PB', 1)\n",
        "                       .replace('PE', 1)\n",
        "                       .replace('AL', 1)\n",
        "                       .replace('SE', 1)\n",
        "                       .replace('BA', 1)\n",
        "                       # Centro\n",
        "                       .replace('MS', 1)\n",
        "                       .replace('GO', 1)\n",
        "                       .replace('DF', 1)\n",
        "                       .replace('MT', 3)\n",
        "                       # Sudeste\n",
        "                       .replace('MG', 4)\n",
        "                       .replace('ES', 4)\n",
        "                       .replace('RJ', 4)\n",
        "                       .replace('SP', 4)\n",
        "                       # Sul\n",
        "                       .replace('PR', 4)\n",
        "                       .replace('SC', 4)\n",
        "                       .replace('RS', 4)\n",
        "                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qweedUbxy2j7"
      },
      "outputs": [],
      "source": [
        "# Categorização dos Cargos para futuros cruzamentos de dados\n",
        "df1['Cargo_Numerico'] = preprocessing.LabelEncoder().fit_transform(df1['Cargo'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGYwdcH9dR-w"
      },
      "outputs": [],
      "source": [
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVXXWwx0Xr3p"
      },
      "outputs": [],
      "source": [
        "# Categorização da situação dos funcionários\n",
        "# 0 significa que o funcionário foi desligado\n",
        "# 1 significa que o funcionário está ativo\n",
        "df2['Situação_Numerico'] = (df2['Situação']\n",
        "                          .replace('Desligado', 0)\n",
        "                          .replace('Ativo', 1)\n",
        "                          .replace('Afastado',1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQPYY0PXQlpI"
      },
      "outputs": [],
      "source": [
        "# Exibir lista de ocorrências das variáveis categóricas\n",
        "# Qtd de ocorrencia de cada uma das categorias\n",
        "print(df2.Situação.unique())\n",
        "df2.Situação.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT-lPA74KQG5"
      },
      "source": [
        "## Derivação\n",
        "Aqui criamos algumas variáveis a mais a partir dos dados que temos para melhorar o modelo preditivo (como criar a idade a partir da data de nascimento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pMgLz5B8rSV"
      },
      "source": [
        "### Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K48oEDY8qwz"
      },
      "outputs": [],
      "source": [
        "# Criação da coluna status, onde \n",
        "# \"0\" é \"desativo\" \n",
        "# \"1\" é \"ativo\"\n",
        "df1['Status'] = (df1['Tipo Saida']\n",
        "                              .fillna(0)\n",
        "                              .replace('RescisaoContratoExp-Dispensa', 1)\n",
        "                              .replace('RescisaoContratoExp-Pedido', 1)\n",
        "                              .replace('DispensasemJustaCausa', 1)\n",
        "                              .replace('PedidodeDemissão', 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGI34GIguOVj"
      },
      "outputs": [],
      "source": [
        "df1['Tipo_Saida_Numerico'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_7RzLGr_XP1"
      },
      "outputs": [],
      "source": [
        "df1['Status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Média Salarial "
      ],
      "metadata": {
        "id": "RwIcYQZD-jVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Media_Salarial'] = -1\n",
        "\n",
        "for i in range(0, len(df1)):\n",
        "  Cargo_da_pessoa = df1['Cargo_Numerico'][i]\n",
        "  df1['Media_Salarial'][i] = df1.query(f'`Cargo_Numerico` == {Cargo_da_pessoa}').mean()['Salario Mês']"
      ],
      "metadata": {
        "id": "6DU1P411-lTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Salario_Comparado'] = 0\n",
        "\n",
        "for item in range(0,len(df1)):\n",
        "    if df1['Media_Salarial'][item] > df1['Salario Mês'][item]:\n",
        "        df1['Salario_Comparado'][item] = 1  \n",
        "df1"
      ],
      "metadata": {
        "id": "oWUfSyR7Bo_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['salario_comparado'] = 0\n",
        "\n",
        "for item in range(0,len(df1)):\n",
        "    if df1['Media_Salarial'][item] > df1['Salario Mês'][item]:\n",
        "        df1['salario_comparado'][item] = 1  \n",
        "df1"
      ],
      "metadata": {
        "id": "V0q94k3mBHIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5oSyTe3ntY"
      },
      "source": [
        "### Jornada de trabalho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cnYyBYp4A37"
      },
      "outputs": [],
      "source": [
        "#Função pega a data de admissão do colaborador e a data do seu desligamento, e encontra o perído entre elas.\n",
        "df1['Tempo de Trabalho'] = (pd.to_datetime(df1['Dt Saida']) - pd.to_datetime(df1['Dt Admissao'])).replace(np.NaN, date.today())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiVA_rmJ5lNO"
      },
      "source": [
        "### Idade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG7pFj2t5mcU"
      },
      "outputs": [],
      "source": [
        "#Ele pega a data de hoje e subtrai da data de nascimento, retornando a idade, np.timedelta64, transforma o retorno da data de dias para ano.\n",
        "df1['Idade'] = ((pd.to_datetime('today')-pd.to_datetime(df1['Dt Nascimento']))/ np.timedelta64(1, 'Y')).astype(int)\n",
        "df1['Idade']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Faixa Etária"
      ],
      "metadata": {
        "id": "q1mnxoZdMrz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['faixa_etaria'] = 0\n",
        "for i in range(0, len(df1)):\n",
        "    if df1['Idade'][i] >= 18 and  df1['Idade'][i] <= 21:\n",
        "        df1['faixa_etaria'][i] = '0'\n",
        "    elif df1['Idade'][i] >= 22 and  df1['Idade'][i] <= 25:\n",
        "        df1['faixa_etaria'][i] = '1'\n",
        "    elif df1['Idade'][i] >= 26 and  df1['Idade'][i] <= 29:\n",
        "        df1['faixa_etaria'][i] = '2'\n",
        "    elif df1['Idade'][i] >= 30 and  df1['Idade'][i] <= 33:\n",
        "        df1['faixa_etaria'][i] = '3'\n",
        "    elif df1['Idade'][i] >= 34 and  df1['Idade'][i] <= 37:\n",
        "        df1['faixa_etaria'][i] = '4'\n",
        "    elif df1['Idade'][i] >= 38 and  df1['Idade'][i] <= 41:\n",
        "        df1['faixa_etaria'][i] = '5'\n",
        "    elif df1['Idade'][i] >= 42 and  df1['Idade'][i] <= 45:\n",
        "        df1['faixa_etaria'][i] = '6'\n",
        "    elif df1['Idade'][i] >= 46 and  df1['Idade'][i] <= 49:\n",
        "        df1['faixa_etaria'][i] = '7'\n",
        "    elif df1['Idade'][i] >= 50 and  df1['Idade'][i] <= 65:\n",
        "        df1['faixa_etaria'][i] = '8'\n"
      ],
      "metadata": {
        "id": "fpdAz2zIM017"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCHS5gyST_lS"
      },
      "source": [
        "###Período de estagnação de reconhecimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ulYDiE0UPyd"
      },
      "source": [
        "O período de estagnação está em dias, e é o período de tempo entre o reconhecimento e o dia de hoje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5utXfhAT9xv"
      },
      "outputs": [],
      "source": [
        "df2['Estagnação'] = ((pd.to_datetime('today')-pd.to_datetime(df2['Data Vigência']))/ np.timedelta64(1, 'D')).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estagnação na df1"
      ],
      "metadata": {
        "id": "akeukyPkVyLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_estagnacao(x): #define a funcao\n",
        "#   df_funcionario = df2[df2['Matricula']==x['Matricula']] #cria um dataframe com apenas os dados que estão nas duas tabelas ao mesmo tempo\n",
        "#   return df_funcionario['Estagnação'].min() #devolve, desse dataframe, apenas o menor valor de estagnação\n",
        "# df1['Estagnação'] = df1.apply(get_estagnacao, axis=1)"
      ],
      "metadata": {
        "id": "GDx1lcPBDkNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contador = 0\n",
        "for matricula in df1['Matricula']:\n",
        "  if matricula in df2['Matricula'].values:\n",
        "    query = df2.query(f'Matricula == {matricula}')\n",
        "    if query['Matricula'].count() > 1:\n",
        "      df1['Estagnação'][contador] = np.array(query['Estagnação']).min()\n",
        "    else:\n",
        "      df1['Estagnação'][contador] = query['Estagnação']\n",
        "  else:\n",
        "    if df1.query(f'Matricula == {matricula}')['Status'][contador] == 1:\n",
        "      df1['Estagnação'][contador] = round(((pd.to_datetime(df1['Dt Saida'][contador])-pd.to_datetime(df1['Dt Admissao'][contador]))/np.timedelta64(1, 'D')))\n",
        "    else:\n",
        "      df1['Estagnação'][contador] = round(((pd.to_datetime('today')-pd.to_datetime(df1['Dt Admissao'][contador]))/np.timedelta64(1, 'D')))\n",
        "\n",
        "  contador += 1"
      ],
      "metadata": {
        "id": "GIM94EDSD6w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1oDzdKj6guG"
      },
      "source": [
        "## Seleção de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUIO4mRM0S8o"
      },
      "source": [
        "### Quantidades de reconhecimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUxkZbvy0YG1"
      },
      "source": [
        "Em ordem: \n",
        "- Pessoas que saíram\n",
        "- Pessoas que não saíram\n",
        "- Pessoas que foram reconhecidas de alguma forma\n",
        "- Pessoas que não foram reconhecidas\n",
        "- Pessoas que saíram e foram reconhecidas\n",
        "- Pessoas que saíram e não foram reconhecidas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGoXQzjynfNB"
      },
      "outputs": [],
      "source": [
        "# Pessoas que saíram: ✔\n",
        "pessoas_desativadas = df1.dropna(subset=['Dt Saida'])['Nome Completo'].unique()\n",
        "qtd_desativados = len(pessoas_desativadas)\n",
        "qtd_desativados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mypGcdFxo005"
      },
      "outputs": [],
      "source": [
        "# Pessoas que não saíram: ✔\n",
        "pessoas_ativas = df1.query('`Dt Saida` == \"\"')['Nome Completo'].unique()\n",
        "len(pessoas_ativas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjaUx6eW8SV4"
      },
      "outputs": [],
      "source": [
        "# Pessoas que foram reconhecidas de alguma forma: ✔\n",
        "pessoas_reconhecidas = df2['Codinome'].unique()\n",
        "len(pessoas_reconhecidas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H5qAXbwB9RW"
      },
      "outputs": [],
      "source": [
        "# Pessoas que não foram reconhecidas: ✔\n",
        "lista_pessoas = df1['Nome Completo'].unique()\n",
        "pessoas_sem_reconhecimento = []\n",
        "for i in range(0, len(lista_pessoas)):\n",
        "  if lista_pessoas[i] in pessoas_reconhecidas:\n",
        "    continue\n",
        "  else:\n",
        "    pessoas_sem_reconhecimento.append(lista_pessoas[i])\n",
        "len(pessoas_sem_reconhecimento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7ykdBXwAoe1"
      },
      "outputs": [],
      "source": [
        "  # Pessoas que foram reconhecidas e saíram ✔\n",
        "pessoas_desativadas_reconhecidas = df2.query('`Situação` == \"Desligado\"')['Codinome'].unique()\n",
        "len(pessoas_desativadas_reconhecidas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzPrseEl9ZAB"
      },
      "outputs": [],
      "source": [
        "# Pessoas que não foram reconhecidas e saíram:\n",
        "pessoas_desativadas_sem_reconhecimento = []\n",
        "for pessoa in pessoas_desativadas:\n",
        "  if pessoa in pessoas_reconhecidas:\n",
        "    continue\n",
        "  else:\n",
        "    pessoas_desativadas_sem_reconhecimento.append(pessoa)\n",
        "print(len(pessoas_desativadas_sem_reconhecimento))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBmEVbgp2_Nw"
      },
      "source": [
        "###Reconhecimento por colaborador\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW8OPyfq3Ogt"
      },
      "outputs": [],
      "source": [
        "num_prom = df2['Codinome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lol1boHn_JOt"
      },
      "outputs": [],
      "source": [
        "num_prom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENX2xW0X-sjA"
      },
      "outputs": [],
      "source": [
        "df2['Reconhecimento Num'] = df2['Codinome'].replace(num_prom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiLiyUnK3q7U"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rkrunmm6vuB"
      },
      "source": [
        "### Gênero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUo5GxS_DgcJ"
      },
      "outputs": [],
      "source": [
        "gen_total = df1.groupby(['Genero_Numerico']).count()\n",
        "gen_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNayySh_Luer"
      },
      "outputs": [],
      "source": [
        "gen_total_masc = gen_total.iloc[0, 1]\n",
        "gen_total_masc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDrlxlLPLy_s"
      },
      "outputs": [],
      "source": [
        "gen_total_fem = gen_total.iloc[1, 1]\n",
        "gen_total_fem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvqhzZDfL5qd"
      },
      "outputs": [],
      "source": [
        "gen_masc_left = gen_total.iloc[0, 3]\n",
        "gen_masc_left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xBrQOo8MTu2"
      },
      "outputs": [],
      "source": [
        "gen_fem_left = gen_total.iloc[1, 3]\n",
        "gen_fem_left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBcyDSm8MpbY"
      },
      "outputs": [],
      "source": [
        "gen_fem_prop = (gen_fem_left/gen_total_fem)*100\n",
        "gen_fem_prop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIGyWzV3NRQG"
      },
      "outputs": [],
      "source": [
        "gen_masc_prop = (gen_masc_left/gen_total_masc)*100\n",
        "gen_masc_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPamyAylaqot"
      },
      "source": [
        "# Saída por estado "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z8p5YOCfBLH"
      },
      "outputs": [],
      "source": [
        "df1['estadoSP'] = 0\n",
        "\n",
        "for item in range(0,len(df1)):\n",
        "    if df1['Estado_Numerico'][item] == 16:\n",
        "        df1['estadoSP'][item] = 1  \n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFqCypbdg2VM"
      },
      "outputs": [],
      "source": [
        "Estado_total = df1.groupby(['estadoSP']).count()\n",
        "Estado_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3JzxI3cg2eh"
      },
      "outputs": [],
      "source": [
        "total_foraSP = Estado_total.iloc[0, 1]\n",
        "total_foraSP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lyNYyxvymE7"
      },
      "outputs": [],
      "source": [
        "total_emSP = Estado_total.iloc[1, 1]\n",
        "total_emSP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LyWvPvfymbA"
      },
      "outputs": [],
      "source": [
        "total_foraSP_off = Estado_total.iloc[0, 3]\n",
        "total_foraSP_off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwL9JalJyznX"
      },
      "outputs": [],
      "source": [
        "total_emSP_off = Estado_total.iloc[1, 3]\n",
        "total_emSP_off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An51rzFzyztK"
      },
      "outputs": [],
      "source": [
        "emSP_prop = (total_emSP_off/total_emSP)*100\n",
        "emSP_prop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyyeRTTU05wf"
      },
      "outputs": [],
      "source": [
        "foraSP_prop = (total_foraSP_off/total_foraSP)*100\n",
        "foraSP_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YfL4V1i6OAd"
      },
      "source": [
        "# Gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMoer3zb9rfy"
      },
      "source": [
        "### Porcentagem de saídas em gênero "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXV-6dUcNdQI"
      },
      "outputs": [],
      "source": [
        "gen_x = ['mulheres', 'homens']\n",
        "gen_y = [gen_fem_prop, gen_masc_prop]\n",
        "\n",
        "plt.bar(gen_x, gen_y)\n",
        "\n",
        "plt.xlabel('Gênero')\n",
        "plt.ylabel('Desligamentos (em %)')\n",
        "plt.title('Desligamentos x Gênero (proporcionalmente)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT8Z3jGZbCHO"
      },
      "source": [
        "# Porcentagem de saída por estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyq8_QRwbG5x"
      },
      "outputs": [],
      "source": [
        "est_x = ['São Paulo', 'Fora de São Paulo']\n",
        "est_y = [emSP_prop,foraSP_prop]\n",
        "\n",
        "plt.bar(est_x, est_y)\n",
        "\n",
        "plt.xlabel('Local')\n",
        "plt.ylabel('Desligamentos (em %)')\n",
        "plt.title('Desligamentos x cidade (proporcionalmente)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwFG1jI-0FzD"
      },
      "source": [
        "# Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoU0qFi89iEM"
      },
      "source": [
        "## Seleção de dados para a modelagem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAEZhxPj9nVa"
      },
      "outputs": [],
      "source": [
        "# Primeiro separamos as pessoas ativas e desativas em dataframes diferentes\n",
        "df_ativas = df1.query('Status == 1')\n",
        "df_desativas = df1.query('Status == 0')\n",
        "df_ativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2MV-89v9uhW"
      },
      "outputs": [],
      "source": [
        "# Dois terços dos ativos e desativos será treino:\n",
        "len(df_ativas) # isso retorna 284 e dois terços disso será treino\n",
        "ativas_treino = df_ativas.head(189) \n",
        "ativas_teste = df_ativas.tail(95)\n",
        "\n",
        "len(df_desativas) # isso retorna 191, dois terços disso será treino\n",
        "desativas_treino = df_desativas.head(127)\n",
        "desativas_teste = df_desativas.tail(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuRRbTSc-Y0P"
      },
      "outputs": [],
      "source": [
        "# Com, isso, podemos juntar os dataframes de treino e teste:\n",
        "df_treino = np.array(pd.merge(ativas_treino, desativas_treino, how = 'outer'))\n",
        "df_teste = np.array(pd.merge(ativas_teste, desativas_teste, how = 'outer'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siYek4yignOE"
      },
      "outputs": [],
      "source": [
        "df1['Status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6YLHBhQ8QlA"
      },
      "source": [
        "## Modelo SVM (support-vector machine)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divisão de dados para treino '30%'\n",
        "x_SVM = df1[['Idade', 'Cargo_Numerico', 'Regiao_Numerico', 'Salario_Comparado','Estagnação']]\n",
        "y_SVM = df1['Status']\n",
        "x_SVM_train, x_SVM_test, y_SVM_train, y_SVM_test = train_test_split(x_SVM,y_SVM,test_size=0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "pz2nwD5xnb-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5jd57Ge_VuA"
      },
      "outputs": [],
      "source": [
        "SVM_model = svm.SVC(gamma='auto')\n",
        "SVM_model.fit(x_SVM_train, y_SVM_train)\n",
        "\n",
        "y_SVM_pred = SVM_model.predict(x_SVM_test)\n",
        "SVM_score = accuracy_score(y_SVM_pred, y_SVM_test)\n",
        "print(y_SVM_pred)\n",
        "print(\"Acurácia: \", SVM_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_4-tSc1_i_7"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_SVM_test, y_SVM_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOfsE-O9W18"
      },
      "source": [
        "## Modelo KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4ZKFQYp93OA"
      },
      "outputs": [],
      "source": [
        "#split dataset\n",
        "x= df1[['Cargo_Numerico', 'Idade']]\n",
        "y= df1['Status']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    test_size = 0.4, \n",
        "                                                    random_state = 0)\n",
        "\n",
        "print(x_train.shape , x_test.shape, y_test.shape, y_train.shape)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPhT4sZ1q6dj"
      },
      "outputs": [],
      "source": [
        "#feature scaling\n",
        "sc_x = StandardScaler()\n",
        "x_train = sc_x.fit_transform(x_train)\n",
        "x_test = sc_x.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N7EuPgvq7Vv"
      },
      "outputs": [],
      "source": [
        "#para definir o k\n",
        "import math\n",
        "math.sqrt(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNLDWB1S95aF"
      },
      "outputs": [],
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=13, metric='euclidean')\n",
        "neigh.fit(x_train, y_train.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KpOpUq8972S"
      },
      "outputs": [],
      "source": [
        "print('Acuracia (treino): ', neigh.score( x_train, y_train ))\n",
        "print('Acuracia (teste): ', neigh.score( x_test, y_test ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae9PcRJkq-tm"
      },
      "outputs": [],
      "source": [
        "y_pred = neigh.predict(x_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K3Kvd04rMkM"
      },
      "outputs": [],
      "source": [
        "#avaliando o modelo\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print (cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3Ll0xECsIhd"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(neigh, x_test, y_test, cmap= \"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3e1QM8zrQwv"
      },
      "outputs": [],
      "source": [
        "print(f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoeFsxAgrSxC"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9c9pKlb_L_0"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QLxJrPo2INGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo Árvore de decisão"
      ],
      "metadata": {
        "id": "NINNy7DtITWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "sqD116wcjqlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df1[['faixa_etaria', 'Salario_Comparado', 'estadoSP', 'Estagnação']]\n",
        "y = df1['Status']\n",
        "\n",
        "print(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "arv = DecisionTreeClassifier(criterion='entropy',random_state=42)\n",
        "arv.fit(x_train, y_train)\n",
        "\n",
        "p = arv.predict(x_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(100, 100))\n",
        "_ = plot_tree(arv, feature_names=x.columns)"
      ],
      "metadata": {
        "id": "9pTDPUhQNvzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(arv, x_test, y_test, cmap='Blues', values_format='.0f')"
      ],
      "metadata": {
        "id": "LhRtgV4Laul0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia usando o status"
      ],
      "metadata": {
        "id": "ToFnlfRwa_Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = accuracy_score(p, y_test)\n",
        "score"
      ],
      "metadata": {
        "id": "2weuSJFba-P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Naive Bayes\n"
      ],
      "metadata": {
        "id": "UL1uzj30KGor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Divisão de dados para treino '30%'\n",
        "x = df1[['Idade', 'Cargo_Numerico', 'Regiao_Numerico','estadoSP', 'salario_comparado']]\n",
        "y = df1['Status']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state = 0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "M51luIxyAcyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics \n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "score = accuracy_score(y_pred, y_test)\n",
        "print('Accuracy:', score)"
      ],
      "metadata": {
        "id": "2HONpmV7lQch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test"
      ],
      "metadata": {
        "id": "ZRrbJERUH_Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "ZXMV_VetIJoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OKW7FlFAIXbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuIxfnxJIZVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo de Regressão Logística"
      ],
      "metadata": {
        "id": "wCpCouAKNS5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo x e y\n",
        "x = df1[['faixa_etaria', 'Cargo_Numerico', 'Regiao_Numerico', 'Estado_Numerico', 'Salario Mês']]\n",
        "# PS: NUNCA ESQUEÇA DE TIRAR A RESPOSTA DO CONJUNTO DE CARACTERÍSTICAS!!!\n",
        "y = df1['Status']\n",
        "# Dividindo dados para treino e dados para teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 42)\n",
        "# Treinando o modelo\n",
        "model = LogisticRegression().fit(x_train, y_train)\n",
        "# Fazendo as predições\n",
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "oTv6cVnKGUOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "pSjfU3M2HWTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "GhubitHsHa3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "u_9XryxhHfTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plot_confusion_matrix(model, x_test, y_test, cmap = 'Blues', values_format='.0f')"
      ],
      "metadata": {
        "id": "axElRrBcHkk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qFCNBBcjHlhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neurais"
      ],
      "metadata": {
        "id": "obVzV0gYPCXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Seed the random number generator\n",
        "        np.random.seed(1)\n",
        "\n",
        "        # Set synaptic weights to a 3x1 matrix,\n",
        "        # with values from -1 to 1 and mean 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Takes in weighted sum of the inputs and normalizes\n",
        "        them through between 0 and 1 through a sigmoid function\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        \"\"\"\n",
        "        The derivative of the sigmoid function used to\n",
        "        calculate necessary weight adjustments\n",
        "        \"\"\"\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \"\"\"\n",
        "        We train the model through trial and error, adjusting the\n",
        "        synaptic weights each time to get a better result\n",
        "        \"\"\"\n",
        "        for iteration in range(training_iterations):\n",
        "            # Pass training set through the neural network\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            # Calculate the error rate\n",
        "            error = training_outputs - output\n",
        "\n",
        "            # Multiply error by input and gradient of the sigmoid function\n",
        "            # Less confident weights are adjusted more through the nature of the function\n",
        "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
        "\n",
        "            # Adjust synaptic weights\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        \"\"\"\n",
        "        Pass inputs through the neural network to get output\n",
        "        \"\"\"\n",
        "        \n",
        "        inputs = inputs.astype(float(1), float(0))\n",
        "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize the single neuron neural network\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Random starting synaptic weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    # The training set, with 4 examples consisting of 3\n",
        "    # input values and 1 output value\n",
        "    training_inputs = df_treino\n",
        "    training_outputs = df_treino\n",
        "\n",
        "    # Train the neural network\n",
        "    neural_network.train(training_inputs, training_outputs, 10000)\n",
        "\n",
        "    print(\"Synaptic weights after training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    A = str(input(\"Input 1: \"))\n",
        "    B = str(input(\"Input 2: \"))\n",
        "    C = str(input(\"Input 3: \"))\n",
        "    \n",
        "    print(\"New situation: input data = \", A, B, C)\n",
        "    print(\"Output data: \")\n",
        "    print(neural_network.think(np.array([A, B, C])))"
      ],
      "metadata": {
        "id": "-6zX2uILPHBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABImSf5yBnA0"
      },
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDLAdCib6C45"
      },
      "outputs": [],
      "source": [
        "from dataprep.eda import create_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqC5gv2Q9QeW"
      },
      "outputs": [],
      "source": [
        "create_report(df1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QJRSivH15GI"
      },
      "source": [
        "#"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7pMgLz5B8rSV",
        "RwIcYQZD-jVv",
        "rX5oSyTe3ntY",
        "eiVA_rmJ5lNO",
        "q1mnxoZdMrz6",
        "BUIO4mRM0S8o",
        "pBmEVbgp2_Nw",
        "4Rkrunmm6vuB",
        "sPamyAylaqot",
        "CMoer3zb9rfy",
        "yT8Z3jGZbCHO",
        "DoU0qFi89iEM",
        "e6YLHBhQ8QlA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}